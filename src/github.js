const { graphql } = require("@octokit/graphql")
const { request } = require("@octokit/request")
const composer = require('./composer')
const { getHyphenatedDate } = require('./date')
const docker = require('./docker')
const mem = require('mem')
const npm = require('./npm')

const findFile = async (token, repo, fileName) => {
  const files = await findFiles(token, repo, fileName)
  if (files.length === 1) {
    return files[0]
  } else if (files.length > 1) {
    const filePaths = files.map(file => file.path)
    console.error(`Too many matches found: ${JSON.stringify(filePaths, null, 2)}`)
  }
  return undefined
}

const findFiles = async (token, repo, fileName, initialPath = '') => {
  const items = await listRepoContentsUsingCache(token, repo, initialPath)
  
  const matchingFiles = []
  const files = items.filter(item => item.type === 'file')
  for (const file of files) {
    if (file.name === fileName) {
      matchingFiles.push(file)
    }
  }
  
  const directories = items.filter(item => item.type === 'dir')
  for (const directory of directories) {
    const matches = await findFiles(token, repo, fileName, directory.path)
    matchingFiles.push(...matches)
  }
  
  return matchingFiles
}

const getContentsOfFileByName = async (token, repo, fileName) => {
  const file = await findFile(token, repo, fileName)
  if (file !== undefined) {
    return getContentsOfFileByDownloadUrl(token, file.download_url)
  }
  return undefined
}

const getContentsOfFilesByName = async (token, repo, fileName) => {
  const files = await findFiles(token, repo, fileName)
  return Promise.all(
    files.map(file => getContentsOfFileByDownloadUrl(
      token,
      file.download_url
    ))
  )
}

const getContentsOfFileByDownloadUrl = async (token, downloadUrl) => {
  console.debug(`Getting contents of ${downloadUrl}`)
  const response = await request(`GET ${downloadUrl}`, {
    headers: {
      authorization: "token " + token,
    },
  })
  return response.data
}

/**
 * Get the base images used in each of the specified GitHub repo's Dockerfiles.
 *
 * @param {string} token - A GitHub personal access token
 * @param {string} repo - A GitHub repo. Example: "silinternational/vulnerability-scanner"
 * @returns {Promise<string[]>}
 */
const getDockerBaseImagesOfRepo = async (token, repo) => {
  const contentsOfFiles = await getContentsOfFilesByName(
    token,
    repo,
    'Dockerfile'
  )
  const allBaseImages = []
  for (const contentsOfFile of contentsOfFiles) {
    const fileBaseImages = docker.getBaseImagesFrom(contentsOfFile)
    allBaseImages.push(...fileBaseImages)
  }
  return allBaseImages
}

/**
 * Get the JavaScript dependencies of the specified GitHub repo.
 *
 * @param {string} token - A GitHub personal access token
 * @param {string} repo - A GitHub repo. Example: "silinternational/vulnerability-scanner"
 * @returns {Promise<undefined | {name: string, version: string}[]>}
 */
const getJavaScriptDependenciesOfRepo = async (token, repo) => {
  const contents = await getContentsOfFileByName(
    token,
    repo,
    'package-lock.json'
  )
  return npm.getDependenciesFromPackageLock(contents)
}

/**
 * Get the PHP dependencies of the specified GitHub repo.
 *
 * @param {string} token - A GitHub personal access token
 * @param {string} repo - A GitHub repo. Example: "silinternational/vulnerability-scanner"
 * @returns {Promise<undefined | {name: string, version: string}[]>}
 */
const getPhpDependenciesOfRepo = async (token, repo) => {
  const contents = await getContentsOfFileByName(
    token,
    repo,
    'composer.lock'
  )
  return composer.getDependenciesFromComposerLock(contents)
}

const getSecurityVulnerabilitiesForPackage = async (token, packageName, ecosystem) => {
  const hyphenatedDate = getHyphenatedDate()
  console.log(`Calling GitHub API for security vulnerabilities for ${packageName}`)
  const data = await graphql({
    query: `query securityVulnerabilities($package: String!, $ecosystem: SecurityAdvisoryEcosystem!) {
      securityVulnerabilities(
        package: $package,
        ecosystem: $ecosystem,
        first: 100,
        orderBy: {field: UPDATED_AT, direction: DESC}
      ) {
        nodes {
          severity
          vulnerableVersionRange
          advisory {
            identifiers {
              type
              value
            }
            permalink
            summary
          }
          package {
            ecosystem
            name
          }
        }
      }
    }`,
    package: packageName,
    ecosystem: ecosystem,
    headers: {
      authorization: "token " + token,
    },
  })
  const vulnerabilities = data.securityVulnerabilities.nodes
  return vulnerabilities.map(vulnerability => ({
    ecosystem: vulnerability.package.ecosystem,
    detailsUrl: vulnerability.advisory.permalink,
    identifiers: listIdentifiers(vulnerability.advisory),
    inspectedOn: hyphenatedDate,
    packageName: vulnerability.package.name,
    severity: vulnerability.severity,
    summary: vulnerability.advisory.summary,
    vulnerableVersionRange: vulnerability.vulnerableVersionRange
  }))
}

/**
 * List the given advisory's identifiers.
 *
 * @param {{ identifiers: [{type,value}] }} advisory
 * @returns {string[]} - Example: ['CVE-1970-00001']
 */
const listIdentifiers = advisory => {
  const identifiers = advisory.identifiers || []
  return identifiers.map(i => i.value).sort()
}

/**
 * Get the security vulnerabilities for the specified PHP library. This will
 * use an in-memory cache to avoid repeated calls for the same library during a
 * single run.
 *
 * @type Function
 * @param {string} token - A GitHub personal access token
 * @param {string} packageName - A Composer/Packagist package name.
 * @param {string} ecosystem - The package management ecosystem of the package.
 *     Examples: "COMPOSER", "NPM"
 * @returns {Promise<{detailsUrl, ecosystem, identifiers, inspectedOn, packageName, severity, summary, vulnerableVersionRange}[]>}
 */
const getSecurityVulnerabilitiesForPackageUsingCache = mem(
  getSecurityVulnerabilitiesForPackage,
  { cacheKey: JSON.stringify }
)

const listRepoContents = async (token, repo, path = '') => {
  const [repoOwner, repoName] = repo.split('/')
  try {
    const response = await request(`GET /repos/:repoOwner/:repoName/contents/:path`, {
      headers: {
        authorization: "token " + token,
      },
      path: path,
      repoOwner: repoOwner,
      repoName: repoName,
    })
    const items = response.data
    return items.map(item => ({
      download_url: item.download_url,
      name: item.name,
      path: item.path,
      type: item.type
    }))
  } catch (e) {
    if (e.message.includes('This repository is empty')) {
      console.warn(`Warning: ${e.message}`)
      return []
    }
    console.error(`Error (${e.status}): ${e.message}`)
    throw e
  }
}
const listRepoContentsUsingCache = mem(
  listRepoContents,
  { cacheKey: JSON.stringify }
)

/**
 * List the GitHub repos for the specified organization that are visible when
 * using the given personal access token.
 *
 * @param {string} token - A GitHub personal access token
 * @param {string} org - A GitHub organization's name
 * @returns {Promise<string[]>} - List of repos. Example: ["silinternational/vulnerability-scanner"]
 */
const listRepos = async (token, org) => {
  const allRepos = []
  const pageSize = 100
  
  let page = 0
  let thereAreMore = true
  while (thereAreMore) {
    page++
    const response = await request("GET /orgs/:org/repos?per_page=:pageSize&page=:page", {
      headers: {
        authorization: "token " + token,
      },
      org: org,
      page: page,
      pageSize: pageSize
    })
    const repos = response.data
    const activeRepos = repos.filter(repo => !repo.archived)
    allRepos.push(...activeRepos)
    thereAreMore = (repos.length === pageSize)
  } 
  
  return allRepos.map(repo => repo.full_name)
}

module.exports = {
  getDockerBaseImagesOfRepo,
  getJavaScriptDependenciesOfRepo,
  getPhpDependenciesOfRepo,
  getSecurityVulnerabilitiesForPackageUsingCache,
  listRepos
}
